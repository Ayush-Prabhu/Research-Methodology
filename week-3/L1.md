# Introduction to Research: Data Analysis Lecture Notes

## Overview
- Welcome to the course on Introduction to Research, focusing on Data Analysis.
- Previous lectures covered the basics of research and literature review.
- This lecture will cover:
  - What is data analysis?
  - Types of analysis.
  - Different types of data encountered in data analysis.
  - Systematic procedures for data analysis.
  - Hands-on examples using R, an open-source software for statistical data analysis.

## Importance of Data Analysis
- Data analysis is integral to any research work.
- Data is collected in various forms across different fields (e.g., engineering, medicine).
- The need for systematic data analysis has grown due to the vast amounts of data generated today.
- Analyzing data involves more than just using software to generate graphs; it requires a theoretical understanding and a systematic approach.

## What is Data Analysis?
- Data analysis involves extracting useful, relevant, and meaningful information from observations.
- Common purposes of data analysis include:
  - **Parameter Estimation**: Inferring unknowns, such as statistical properties (mean, variance, etc.).
  - **Model Development**: Creating models to predict variables of interest.
  - **Feature Extraction**: Identifying important features in data (e.g., peaks in ECG data).
  - **Classification**: Grouping data based on characteristics (e.g., image analysis).
  - **Hypothesis Testing**: Testing claims about data (e.g., average temperature).
  - **Fault Detection**: Identifying anomalies in data (e.g., medical imaging).
 
    ![Where does analysis fit in?](https://github.com/user-attachments/assets/4aa7a01f-4851-4501-abe3-5382631c6d5b)


## Types of Data Analysis
- **Exploratory vs. Confirmatory**:
  - Exploratory: No upfront hypothesis; understanding data through visual and descriptive statistics.
  - Confirmatory: Testing a specific hypothesis using data.
  
- **Quantitative vs. Qualitative**:
  - Qualitative: Analyzing trends and features.
  - Quantitative: Focusing on numerical results.

- **Descriptive vs. Inferential**:
  - Descriptive: Summarizing data without making predictions.
  - Inferential: Making predictions or inferences based on data.

- **Predictive vs. Prescriptive**:
  - Predictive: Forecasting future outcomes based on data.
  - Prescriptive: Understanding causes of events and suggesting actions.

## Types of Data
- **Deterministic vs. Stochastic**:
  - Deterministic: Data generated from a predictable process.
  - Stochastic: Data with inherent randomness or uncertainty.

- **Numerical vs. Categorical**: 
  - Numerical: Quantitative data (e.g., temperature).
  - Categorical: Qualitative data (e.g., gender).

## Data Generating Process (DGP)
- The DGP is crucial in understanding the nature of data.
- Deterministic processes have predictable outcomes, while stochastic processes involve uncertainty.
- Understanding the DGP helps in choosing appropriate analysis methods.

## Importance of Assumptions
- Assumptions about the DGP affect the analysis, tools, and interpretations.
- Analysts must be clear about their assumptions to ensure valid results.

## Data Analysis Procedure
1. **Preliminary Steps**:
   - Visualization: Plotting data to identify patterns and anomalies.
   - Quality Check: Assessing data quality (e.g., outliers, missing values).
   - Pre-processing: Cleaning and preparing data for analysis.

2. **Core Analysis**:
   - Modeling: Estimating parameters or building predictive models.
   - Iterative Nature: Data analysis is often non-linear; analysts may need to revisit earlier steps.

3. **Final Assessment**:
   - Hypothesis Testing: Validating results statistically.
   - Reporting: Presenting findings with confidence intervals and error estimates.

## Key Terminology
- **Population vs. Sample**: Population refers to all possible observations; a sample is a subset of those observations.
- **Statistic vs. Estimator**: A statistic is a mathematical function of data; an estimator is designed to estimate a specific parameter.
- **Truth vs. Estimate**: Truth refers to true population charachteristics in descriptive statistics or to that of true parameters. Estimate is inferred value of unkown parameter.
- **Bias vs. Variability**: Bias is systematic error; variability measures the spread of estimates.
- **Ensemble vs. Sample average**: Ensemble avg. (Expectation) is average accross population at a single point in time, sample avg is avg over all observations for one record.
- **Bias**: Measure of accuracy. It is systematic error by virtue of estimation method.
$$
\text{Bias}(\hat{\theta}) = E(\hat{\theta}) - \theta_0
$$
Where:
- \( E(\hat{\theta}) \) is the ensemble average of the estimator.
- \( \theta_0 \) is the true parameter value.

- **Variability**: Measure of precision.
  $$
\text{Var}(\hat{\theta}) = E\left(\hat{\theta} - E(\hat{\theta})\right)^2
$$
Data analysis process is iterative.

## Preliminary questions in analysis
- What type of analysis is required?
- Where does the data come from?
- How was the data acquired?
- How informative is the data?
- What assumptions are being made on the data generating process?

## Preparing data
- Preprocessing: Cleaning outliers, reconcilation, synchronization of timestamps.
- Partitioning: Training vs test data sets.
- Assessing quantization or compression errors (for data from historians)

## Core steps
- Select domain of analysis (ex: transformation of data)
- Dimensionality reduction (multivariate data analysis tools-PCA,NMF)
- Choose right Mathematical/Statistical tool (Significance level in hypothesis test, source of variability in ANOVA, regressor set and model structure in modelling)
- Always factor in domain knowledge at each step.

## Assessing and reporting results
- Compute confidence regions and errors in estimates.
- Conduct hypothesis tests on estimates
- Cross validate models
- If multiple models are identified, use a mix of information-theoretic measures (ex: Akaike Info Criterion) and end-use criteria to select appropriate model. Best working model is preferred not right model.
- Confidence bound should be provided for forecasts.

## Conclusion
- Data analysis is both a science and an art.
- It requires careful consideration of assumptions, data quality, and systematic procedures.
- The final results should be statistically sound and well-justified.

## References
- Random Data Analysis
- Applied Probability and Statistics (Johnson, Montgomery, Runger)
- Fundamentals of Probability and Statistics for Engineers (Ogunnaike)

## Next Steps
- Hands-on examples in R to supplement the lecture.
